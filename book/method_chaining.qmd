# Method Chaining

Many people don't need to be told why method chaining is nice. Many languages make it easy to write
`thing.min().abs().str()` instead of `str(abs(min(thing)))`.

But the Python standard library tends to prefer the ugly way, so if you've spent a lot of time doing vanilla Python stuff, you may have become accustomed to writing
nasty nested function calls or declaring intermediate variables like `min_thing`. This is sad because a sensible degree of method chaining can make code a lot easier to read.

It's not always easy for libraries to accommodate method chaining - in fancy terms, to be [fluent interfaces](https://en.wikipedia.org/wiki/Fluent_interface). Even Pandas used to be much less fluent:
when *Modern Pandas* was released, methods like `assign` and `pipe` were quite recent.

Fortunately Polars is very fluent. The expression API provides a very elegant way to do a bunch of stuff to a dataframe in one fell swoop, and Polars mostly doesn't mutate dataframes in-place (method chaining with side effects is usually a bad idea).

Let's see how this looks in practice by cleaning up the flight data we gathered in @sec-indexing.

## Setup

``` {python}
from pathlib import Path
import polars as pl
import pandas as pd

pl.Config.set_tbl_rows(5)
pd.options.display.max_rows = 5

data_dir = Path("../data")
extracted = data_dir / "On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2022_1.csv"
```

## Extract city names

The dataset has two columns that look like `$city, $state`. Let's define a function that removes the state part from these columns. There's no method chaining yet but we do have a few things to talk about while we're here:

::: {.panel-tabset}
## Polars

``` {python}
def extract_city_name_pl() -> pl.Expr:
    """
    Chicago, IL -> Chicago for OriginCityName and DestCityName
    """
    cols = ["OriginCityName", "DestCityName"]
    # note that lists are OK in Polars if they have the same data type
    return pl.col(cols).str.split(",").arr.get(0)
```

## Pandas

``` {python}
def extract_city_name_pd(df: pd.DataFrame) -> pl.DataFrame:
    """
    Chicago, IL -> Chicago for OriginCityName and DestCityName
    """
    cols = ["OriginCityName", "DestCityName"]
    return df.assign(**{col: df[col].str.split(",", regex=False).str[0] for col in cols})
```

:::

Some things to note:

1. Our Pandas function adds columns to a dataframe, while our Polars function simply generates a Polars *expression*.
You'll find it's often easier to pass around `Expr`s than dataframes because: 
    i. They work on both `DataFrame` and `LazyFrame`, and they aren't bound to any particular data.
    ii. Polars performs better if you put everything in one `.select` or `.with_columns` call, rather than calling `.select` multiple times. If you pass around expressions, this pattern is easy.
2.  Polars is fast and convenient for doing the same thing to multiple columns. We can pass a list of columns to `pl.col`
    and then call a method on that `pl.col` as if it were one column. When the expression gets executed it will be parallelized by Polars.

    Meanwhile in Pandas we have to loop through the columns to create a dictionary of kwargs for `.assign`. This is not parallel. (We could use `.apply` with `axis=0` instead but this would still take place sequentially and isn't any easier to read, in my opinion).
3.  Calling `.str.split` in Polars creates a column where every element is a list. This kind of data is annoying in Pandas
    because it's slow and awkward to work with - notice how the most convenient way to get the first element of a list column in Pandas is to call `.str[0]`, even though this is a list, not a string ðŸ¤¯
    
    I'm not sure if that's even supposed to work. In contrast, Polars actually has first class support for list columns, and they are fast **as long as they don't have mixed types.**

::: {.panel-tabset}
## Polars

``` {python}
def time_col_pl(col: str) -> pl.Expr:
    col_expr = pl.col(col)
    return (
        pl.when(col_expr == "2400")
        .then("0000")
        .otherwise(col_expr)
        .str.strptime(pl.Time, "%H%M", strict=True)
        .alias(col)
    )


def time_to_datetime_pl(columns: list[str]) -> list[pl.Expr]:
    """
    Combine all time items into datetimes.

    2014-01-01,0914 -> 2014-01-01 09:14:00
    """
    date_val = pl.col("FlightDate").dt.epoch("us")
    return [
        (date_val + time_col_pl(col).to_physical() // 1000)
        .cast(pl.Datetime)
        .alias(col)
        for col in columns
    ]
```

## Pandas

``` {python}
def time_col_pd(col: str, df: pd.DataFrame) -> pd.Series:
    timepart = df[col].replace("2400", "0000")
    return pd.to_datetime(df["FlightDate"] + ' ' +
                            timepart.str.slice(0, 2) + ':' +
                            timepart.str.slice(2, 4),
                            errors='coerce')

def time_to_datetime_pd(df: pd.DataFrame, columns: list[str]) -> pd.DataFrame:
    '''
    Combine all time items into datetimes.

    2014-01-01,0914 -> 2014-01-01 09:14:00
    '''
    return df.assign(**{col: time_col_pd(col, df) for col in columns})
```

:::

The Pandas version concatenates the date and time strings then parses the datetime string.
We could do the same in Polars but I wanted to show you the `pl.Date` and `pl.Time` dtypes, which Pandas lacks.
It turns out that combining `pl.Date` and `pl.Time` isn't that straightforward: I had to convert them both to microseconds, add them and then cast as `pl.Datetime`.


## Brining It All Back Home

It's time for some method chaining. First, some common variables for both the Polars and Pandas code:

``` {python}
category_cols = (
    "Dest",
    "Tail_Number",
    "IATA_CODE_Reporting_Airline",
    "CancellationCode",
)
time_cols = ("DepTime", "ArrTime", "CRSArrTime", "CRSDepTime")
cols = (
    category_cols
    + time_cols
    + (
        "FlightDate",
        "Flight_Number_Reporting_Airline",
        "OriginCityName",
        "DestCityName",
        "Origin",
        "DepDelay",
    )
)
```

Now to read the CSVs and use the functions we defined above:

::: {.panel-tabset}
## Polars

``` {python}
dtypes_pl = (
    {col: pl.Categorical for col in category_cols}
    | {"FlightDate": pl.Date}
    | {col: pl.Utf8 for col in time_cols}
)
df_pl = (
    pl.scan_csv(extracted, dtypes=dtypes_pl, null_values="")
    .select(cols)
    .with_columns([extract_city_name_pl(), *time_to_datetime_pl(time_cols)])
    .collect()
)
df_pl.head()
```

## Pandas

``` {python}
dtypes_pd = (
    {col: pd.CategoricalDtype() for col in category_cols}
    | {col: pd.StringDtype() for col in time_cols}
)
df_pd = (
    pd.read_csv(extracted, dtype=dtypes_pd, usecols=cols, na_values="", engine="pyarrow")
    .pipe(extract_city_name_pd)
    .pipe(time_to_datetime_pd, list(time_cols))
    .assign(FlightDate=lambda df: pd.to_datetime(df["FlightDate"]))
)
df_pd.head()
```

:::